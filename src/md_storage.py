"""
–ú–æ–¥—É–ª—å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞—Ä—Ö–∏–≤–æ–º MD –æ—Ç—á–µ—Ç–æ–≤.
–†–µ–∞–ª–∏–∑—É–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –∏ –ø–æ–∏—Å–∫ –æ—Ç—á–µ—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
"""

import os
import json
import logging
import threading
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from pathlib import Path

from config import MD_REPORTS_DIR
from constants import MD_FILE_PREFIX, MD_FILE_EXTENSION, INDEX_FILE_NAME
from utils import count_tokens


@dataclass
class ReportMetadata:
    """–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç–∞."""
    file_path: str
    user_id: int
    username: str
    timestamp: str
    question: str
    size_bytes: int
    tokens: int
    search_type: str
    report_number: int = 0  # default=0 –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏


class MDStorageManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è MD –æ—Ç—á–µ—Ç–∞–º–∏."""

    def __init__(self):
        self.reports_dir = Path(MD_REPORTS_DIR)
        self.ensure_reports_directory()

        # Thread-safe locks –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        self._user_locks: Dict[int, threading.Lock] = {}
        self._lock_manager = threading.Lock()

    def ensure_reports_directory(self) -> None:
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –æ—Ç—á–µ—Ç–æ–≤ –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        try:
            self.reports_dir.mkdir(parents=True, exist_ok=True)
            logging.debug(f"Reports directory ensured: {self.reports_dir}")
        except Exception as e:
            logging.error(f"Failed to create reports directory {self.reports_dir}: {e}")
            raise

    def ensure_user_directory(self, user_id: int) -> Path:
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        user_dir = self.reports_dir / f"user_{user_id}"
        try:
            user_dir.mkdir(parents=True, exist_ok=True)
            return user_dir
        except Exception as e:
            logging.error(f"Failed to create user directory {user_dir}: {e}")
            raise

    def _get_user_lock(self, user_id: int) -> threading.Lock:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å lock –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (thread-safe)."""
        with self._lock_manager:
            if user_id not in self._user_locks:
                self._user_locks[user_id] = threading.Lock()
            return self._user_locks[user_id]

    def _get_next_report_number(self, user_id: int) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä –æ—Ç—á–µ—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (thread-safe)."""
        lock = self._get_user_lock(user_id)
        with lock:
            # –ê—Ç–æ–º–∞—Ä–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ max + –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç
            user_reports = self.get_user_reports(user_id, limit=None)
            if not user_reports:
                return 1

            max_number = max(
                (r.report_number for r in user_reports if r.report_number > 0),
                default=0
            )
            return max_number + 1

    def generate_filename(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{MD_FILE_PREFIX}_{timestamp}{MD_FILE_EXTENSION}"

    def create_md_content(
        self,
        content: str,
        username: str,
        user_id: int,
        question: str,
        search_type: str
    ) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ MD —Ñ–∞–π–ª–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —à–∞–±–ª–æ–Ω—É."""
        timestamp = datetime.now().strftime("%d.%m.%Y %H:%M")

        md_content = f"""# –û—Ç—á–µ—Ç VoxPersona
**–î–∞—Ç–∞:** {timestamp}
**–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å:** @{username} (ID: {user_id})
**–ó–∞–ø—Ä–æ—Å:** {question}
**–¢–∏–ø –ø–æ–∏—Å–∫–∞:** {search_type}

---

{content}
"""
        return md_content

    def save_md_report(
        self,
        content: str,
        user_id: int,
        username: str,
        question: str,
        search_type: str
    ) -> Optional[str]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç MD –æ—Ç—á–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É."""
        try:
            user_dir = self.ensure_user_directory(user_id)
            filename = self.generate_filename()
            file_path = user_dir / filename

            # –°–æ–∑–¥–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ MD —Ñ–∞–π–ª–∞
            md_content = self.create_md_content(content, username, user_id, question, search_type)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(md_content)

            # –ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –Ω–æ–º–µ—Ä (thread-safe)
            report_number = self._get_next_report_number(user_id)

            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å
            metadata = ReportMetadata(
                file_path=str(file_path.relative_to(self.reports_dir)),
                user_id=user_id,
                username=username,
                timestamp=datetime.now().isoformat(),
                question=question,
                size_bytes=len(md_content.encode('utf-8')),
                tokens=count_tokens(content),
                search_type=search_type,
                report_number=report_number
            )

            self.update_reports_index(metadata)

            logging.info(f"Saved MD report: {file_path}")
            return str(file_path)

        except Exception as e:
            logging.error(f"Failed to save MD report: {e}")
            return None

    def load_reports_index(self) -> List[ReportMetadata]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –æ—Ç—á–µ—Ç–æ–≤."""
        index_path = self.reports_dir / INDEX_FILE_NAME

        if not index_path.exists():
            return []

        try:
            with open(index_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            reports = []
            valid_fields = set(ReportMetadata.__dataclass_fields__.keys())

            for item in data:
                try:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è
                    filtered = {k: v for k, v in item.items() if k in valid_fields}
                    report = ReportMetadata(**filtered)
                    reports.append(report)
                except Exception as e:
                    logging.warning(f"Skipped invalid report {item.get('file_path', 'unknown')}: {e}")
                    continue

            return reports
        except Exception as e:
            logging.error(f"Failed to load reports index: {e}")
            return []

    def save_reports_index(self, reports: List[ReportMetadata]) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω–¥–µ–∫—Å –æ—Ç—á–µ—Ç–æ–≤."""
        index_path = self.reports_dir / INDEX_FILE_NAME

        try:
            data = [asdict(report) for report in reports]

            with open(index_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            return True
        except Exception as e:
            logging.error(f"Failed to save reports index: {e}")
            return False

    def update_reports_index(self, new_report: ReportMetadata) -> bool:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω–¥–µ–∫—Å –æ—Ç—á–µ—Ç–æ–≤, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–π –æ—Ç—á–µ—Ç."""
        try:
            reports = self.load_reports_index()
            reports.append(new_report)
            return self.save_reports_index(reports)
        except Exception as e:
            logging.error(f"Failed to update reports index: {e}")
            return False

    def get_user_reports(self, user_id: int, limit: Optional[int] = 10) -> List[ReportMetadata]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—á–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)."""
        try:
            all_reports = self.load_reports_index()
            user_reports = [r for r in all_reports if r.user_id == user_id]

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
            user_reports.sort(key=lambda x: x.timestamp, reverse=True)

            return user_reports if limit is None else user_reports[:limit]
        except Exception as e:
            logging.error(f"Failed to get user reports: {e}")
            return []

    def get_report_stats(self, user_id: Optional[int] = None) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—Ç—á–µ—Ç–æ–≤."""
        try:
            all_reports = self.load_reports_index()

            if user_id is not None:
                reports = [r for r in all_reports if r.user_id == user_id]
            else:
                reports = all_reports

            stats = {
                "total_reports": len(reports),
                "total_size_bytes": sum(r.size_bytes for r in reports),
                "total_tokens": sum(r.tokens for r in reports),
                "fast_searches": len([r for r in reports if r.search_type == "fast"]),
                "deep_searches": len([r for r in reports if r.search_type == "deep"]),
            }

            if reports:
                stats["avg_size_bytes"] = stats["total_size_bytes"] / len(reports)
                stats["avg_tokens"] = stats["total_tokens"] / len(reports)
            else:
                stats["avg_size_bytes"] = 0
                stats["avg_tokens"] = 0

            return stats
        except Exception as e:
            logging.error(f"Failed to get report stats: {e}")
            return {}

    def get_report_file_path(self, relative_path: str) -> Optional[Path]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç—á–µ—Ç–∞."""
        try:
            full_path = self.reports_dir / relative_path
            if full_path.exists():
                return full_path
            return None
        except Exception as e:
            logging.error(f"Failed to get report file path: {e}")
            return None

    def format_user_reports_for_display(self, user_id: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –æ—Ç—á–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
        reports = self.get_user_reports(user_id, limit=10)

        if not reports:
            return "üìÅ **–í–∞—à–∏ –æ—Ç—á–µ—Ç—ã:**\n\n–£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤."

        result = f"üìÅ **–í–∞—à–∏ –æ—Ç—á–µ—Ç—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–µ {len(reports)}):**\n\n"

        for i, report in enumerate(reports, 1):
            timestamp = datetime.fromisoformat(report.timestamp).strftime("%d.%m.%Y %H:%M")
            question_preview = report.question[:60] + "..." if len(report.question) > 60 else report.question
            search_icon = "‚ö°" if report.search_type == "fast" else "üîç"
            size_kb = report.size_bytes / 1024

            result += f"{i}. {search_icon} **{timestamp}**\n"
            result += f"   üìù {question_preview}\n"
            result += f"   üìä {report.tokens:,} —Ç–æ–∫–µ–Ω–æ–≤, {size_kb:.1f} KB\n\n"

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = self.get_report_stats(user_id)
        result += f"üìà **–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n"
        result += f"üìÑ –í—Å–µ–≥–æ –æ—Ç—á–µ—Ç–æ–≤: {stats['total_reports']}\n"
        result += f"üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {stats['total_size_bytes'] / (1024*1024):.2f} MB\n"
        result += f"üìù –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {stats['total_tokens']:,}\n"

        return result

    def cleanup_old_reports(self, days_old: int = 30) -> int:
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –æ—Ç—á–µ—Ç—ã (—Å—Ç–∞—Ä—à–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–Ω–µ–π)."""
        try:
            cutoff_date = datetime.now().timestamp() - (days_old * 24 * 3600)
            reports = self.load_reports_index()

            reports_to_keep = []
            deleted_count = 0

            for report in reports:
                report_date = datetime.fromisoformat(report.timestamp).timestamp()

                if report_date >= cutoff_date:
                    reports_to_keep.append(report)
                else:
                    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
                    file_path = self.get_report_file_path(report.file_path)
                    if file_path and file_path.exists():
                        file_path.unlink()
                        deleted_count += 1
                        logging.info(f"Deleted old report: {file_path}")

            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω–¥–µ–∫—Å
            self.save_reports_index(reports_to_keep)

            logging.info(f"Cleanup completed: {deleted_count} old reports deleted")
            return deleted_count

        except Exception as e:
            logging.error(f"Failed to cleanup old reports: {e}")
            return 0

    def validate_integrity(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏–≤–∞ –æ—Ç—á–µ—Ç–æ–≤."""
        try:
            reports = self.load_reports_index()

            result = {
                "total_reports": len(reports),
                "existing_files": 0,
                "missing_files": 0,
                "orphaned_files": 0,
                "missing_file_paths": [],
                "orphaned_file_paths": []
            }

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
            for report in reports:
                file_path = self.get_report_file_path(report.file_path)
                if file_path and file_path.exists():
                    result["existing_files"] += 1
                else:
                    result["missing_files"] += 1
                    result["missing_file_paths"].append(report.file_path)

            # –ò—â–µ–º —Ñ–∞–π–ª—ã –±–µ–∑ –∑–∞–ø–∏—Å–µ–π –≤ –∏–Ω–¥–µ–∫—Å–µ
            indexed_paths = {report.file_path for report in reports}

            for user_dir in self.reports_dir.glob("user_*"):
                if user_dir.is_dir():
                    for md_file in user_dir.glob(f"*{MD_FILE_EXTENSION}"):
                        relative_path = str(md_file.relative_to(self.reports_dir))
                        if relative_path not in indexed_paths:
                            result["orphaned_files"] += 1
                            result["orphaned_file_paths"].append(relative_path)

            return result

        except Exception as e:
            logging.error(f"Failed to validate integrity: {e}")
            return {"error": str(e)}


    # ============================================================================
    #       ‚úÖ –ù–û–í–´–ï –ú–ï–¢–û–î–´ –¥–ª—è "–ú–æ–∏ –æ—Ç—á–µ—Ç—ã v2" (backend-developer)
    # ============================================================================

    def export_reports_list_to_txt(self, user_id: int) -> Optional[str]:
        """
        –°–æ–∑–¥–∞–µ—Ç TXT —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –æ—Ç—á–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

        –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞:
        ============================================================
        –°–ü–ò–°–û–ö –û–¢–ß–ï–¢–û–í
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: 10.10.2025 16:00
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—á–µ—Ç–æ–≤: 5
        ============================================================

        [1] 10.10.2025 15:30 - voxpersona_20251010_153000.txt
            –í–æ–ø—Ä–æ—Å: –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
            –ü—É—Ç—å: user_12345/voxpersona_20251010_153000.txt
            –†–∞–∑–º–µ—Ä: 45.2 KB | –¢–æ–∫–µ–Ω—ã: 12,345 | –¢–∏–ø: ‚ö° –ë—ã—Å—Ç—Ä—ã–π

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É TXT —Ñ–∞–π–ª—É –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ—Ç –æ—Ç—á–µ—Ç–æ–≤
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º –æ—Ç—á–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            reports = self.get_user_reports(user_id, limit=None)

            if not reports:
                return None

            # –ü–ï–†–ï–î —Å–æ–∑–¥–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞ - —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ
            user_dir = self.ensure_user_directory(user_id)
            old_files = list(user_dir.glob("reports_list_*.txt"))
            for old_file in old_files:
                try:
                    old_file.unlink()
                    logging.info(f"Deleted old reports list: {old_file}")
                except Exception as e:
                    logging.warning(f"Failed to delete {old_file}: {e}")

            # 2. –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç
            lines = []

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            separator = "=" * 60
            current_time = datetime.now().strftime("%d.%m.%Y %H:%M")

            lines.append(separator)
            lines.append("–°–ü–ò–°–û–ö –û–¢–ß–ï–¢–û–í")
            lines.append(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {current_time}")
            lines.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—á–µ—Ç–æ–≤: {len(reports)}")
            lines.append(separator)
            lines.append("")

            # –û—Ç—á–µ—Ç—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º report_number –≤–º–µ—Å—Ç–æ enumerate
            for report in reports:
                timestamp = datetime.fromisoformat(report.timestamp).strftime("%d.%m.%Y %H:%M")
                filename = Path(report.file_path).name
                search_icon = "‚ö° –ë—ã—Å—Ç—Ä—ã–π" if report.search_type == "fast" else "üîç –ì–ª—É–±–æ–∫–∏–π"
                size_kb = report.size_bytes / 1024
                question_preview = report.question[:50]

                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –Ω–æ–º–µ—Ä
                lines.append(f"[{report.report_number}] {timestamp} - {filename}")
                lines.append(f"    –í–æ–ø—Ä–æ—Å: {question_preview}")
                lines.append(f"    –ü—É—Ç—å: {report.file_path}")
                lines.append(f"    –†–∞–∑–º–µ—Ä: {size_kb:.1f} KB | –¢–æ–∫–µ–Ω—ã: {report.tokens:,} | –¢–∏–ø: {search_icon}")
                lines.append("")

            content = "\n".join(lines)

            # 3. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"reports_list_{timestamp}.txt"
            file_path = user_dir / filename

            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)

            logging.info(f"[MDStorage] Exported reports list to {file_path}")
            return str(file_path)

        except Exception as e:
            logging.error(f"[MDStorage] Failed to export reports list: {e}")
            return None

    def get_report_by_index(self, user_id: int, index: int) -> Optional[ReportMetadata]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ 1-based –∏–Ω–¥–µ–∫—Å—É.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            index: 1-based –∏–Ω–¥–µ–∫—Å (1 = –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç—á–µ—Ç, N = –ø–µ—Ä–≤—ã–π –æ—Ç—á–µ—Ç)

        Returns:
            ReportMetadata –∏–ª–∏ None –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –æ—Ç—á–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–µ)
            reports = self.get_user_reports(user_id, limit=None)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω (1-based)
            if index < 1 or index > len(reports):
                logging.warning(f"[MDStorage] Report index {index} out of range for user {user_id}")
                return None

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—á–µ—Ç (index - 1 –¥–ª—è 0-based —Å–ø–∏—Å–∫–∞)
            return reports[index - 1]

        except Exception as e:
            logging.error(f"[MDStorage] Failed to get report by index: {e}")
            return None

    def rename_report(self, user_id: int, index: int, new_name: str) -> bool:
        """
        –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç question –æ—Ç—á–µ—Ç–∞.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            index: 1-based –∏–Ω–¥–µ–∫—Å –æ—Ç—á–µ—Ç–∞
            new_name: –ù–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (question)

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º –æ—Ç—á–µ—Ç –ø–æ –∏–Ω–¥–µ–∫—Å—É
            report = self.get_report_by_index(user_id, index)

            if not report:
                logging.error(f"[MDStorage] Report index {index} not found for user {user_id}")
                return False

            # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å—å –∏–Ω–¥–µ–∫—Å
            all_reports = self.load_reports_index()

            # 3. –ù–∞—Ö–æ–¥–∏–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –Ω—É–∂–Ω—ã–π –æ—Ç—á–µ—Ç
            updated = False
            for r in all_reports:
                if r.user_id == user_id and r.file_path == report.file_path:
                    r.question = new_name.strip()
                    updated = True
                    break

            if not updated:
                logging.error(f"[MDStorage] Failed to find report in index: {report.file_path}")
                return False

            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            success = self.save_reports_index(all_reports)

            if success:
                logging.info(f"[MDStorage] Renamed report #{index} for user {user_id}: '{report.question}' -> '{new_name}'")

            return success

        except Exception as e:
            logging.error(f"[MDStorage] Failed to rename report: {e}")
            return False

    def delete_report(self, user_id: int, index: int) -> bool:
        """
        –£–¥–∞–ª—è–µ—Ç –æ—Ç—á–µ—Ç (—Ñ–∞–π–ª + –∑–∞–ø–∏—Å—å –∏–∑ index.json).

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            index: 1-based –∏–Ω–¥–µ–∫—Å –æ—Ç—á–µ—Ç–∞

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –µ—Å–ª–∏ –æ—à–∏–±–∫–∞
        """
        try:
            # 1. –ü–æ–ª—É—á–∞–µ–º –æ—Ç—á–µ—Ç –ø–æ –∏–Ω–¥–µ–∫—Å—É
            report = self.get_report_by_index(user_id, index)

            if not report:
                logging.error(f"[MDStorage] Report index {index} not found for user {user_id}")
                return False

            # 2. –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
            file_path = self.get_report_file_path(report.file_path)

            if file_path and file_path.exists():
                file_path.unlink()
                logging.info(f"[MDStorage] Deleted report file: {file_path}")
            else:
                logging.warning(f"[MDStorage] Report file not found: {report.file_path}")

            # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å
            all_reports = self.load_reports_index()

            # 4. –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å—å –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
            updated_reports = [
                r for r in all_reports
                if not (r.user_id == user_id and r.file_path == report.file_path)
            ]

            # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            success = self.save_reports_index(updated_reports)

            if success:
                logging.info(f"[MDStorage] Deleted report #{index} for user {user_id}")

            return success

        except Exception as e:
            logging.error(f"[MDStorage] Failed to delete report: {e}")
            return False


    def find_orphaned_reports(self, user_id: int) -> List[str]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç MD –æ—Ç—á–µ—Ç—ã –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –Ω–∏ —Å –æ–¥–Ω–∏–º —á–∞—Ç–æ–º.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –æ—Å–∏—Ä–æ—Ç–µ–≤—à–∏–º MD —Ñ–∞–π–ª–∞–º
        """
        from conversation_manager import conversation_manager

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ MD —Ñ–∞–π–ª—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        all_reports = self.get_user_reports(user_id, limit=None)

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversations = conversation_manager.list_conversations(user_id)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ file_path –∏–∑ –≤—Å–µ—Ö —á–∞—Ç–æ–≤
        linked_files = set()
        for conv_meta in conversations:
            conv = conversation_manager.load_conversation(user_id, conv_meta.conversation_id)
            if conv:
                for msg in conv.messages:
                    if msg.file_path:
                        linked_files.add(msg.file_path)

        # –ù–∞—Ö–æ–¥–∏–º –æ—Å–∏—Ä–æ—Ç–µ–≤—à–∏–µ
        orphaned = [
            report.file_path
            for report in all_reports
            if report.file_path not in linked_files
        ]

        return orphaned

    def cleanup_orphaned_reports(self, user_id: int) -> int:
        """
        –£–¥–∞–ª—è–µ—Ç –æ—Å–∏—Ä–æ—Ç–µ–≤—à–∏–µ MD –æ—Ç—á–µ—Ç—ã.

        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        orphaned = self.find_orphaned_reports(user_id)
        deleted_count = 0

        for file_path in orphaned:
            try:
                full_path = self.get_report_file_path(file_path)
                if full_path and full_path.exists():
                    full_path.unlink()
                    deleted_count += 1
                    logging.info(f"Cleaned up orphaned MD file: {file_path}")
            except Exception as e:
                logging.warning(f"Failed to delete orphaned file {file_path}: {e}")

        # –û–±–Ω–æ–≤–ª—è–µ–º index.json - —É–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ –æ–± —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
        if deleted_count > 0:
            self._remove_from_index(orphaned)

        logging.info(f"Cleaned up {deleted_count} orphaned reports for user {user_id}")
        return deleted_count

    def _remove_from_index(self, file_paths: List[str]):
        """–£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å–∏ –æ–± —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –∏–∑ index.json."""
        try:
            index_file = self.reports_dir / INDEX_FILE_NAME
            if not index_file.exists():
                return

            with open(index_file, 'r', encoding='utf-8') as f:
                reports = json.load(f)

            # –§–∏–ª—å—Ç—Ä—É–µ–º —É–¥–∞–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            file_paths_set = set(file_paths)
            updated_reports = [
                report for report in reports
                if report.get('file_path') not in file_paths_set
            ]

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            with open(index_file, 'w', encoding='utf-8') as f:
                json.dump(updated_reports, f, ensure_ascii=False, indent=2)

            logging.info(f"Removed {len(reports) - len(updated_reports)} entries from MD index")

        except Exception as e:
            logging.error(f"Failed to update MD index: {e}")



# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞
md_storage_manager = MDStorageManager()
