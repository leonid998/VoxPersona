import logging
import threading
from openai import PermissionDeniedError as OpenAIPermissionError
from pyrogram import Client
from pyrogram.enums import ParseMode
import re
import asyncio
import aiohttp
from pathlib import Path
from docx import Document
import os
from typing import List

from config import ANTHROPIC_API_KEY, ANTHROPIC_API_KEY_2, ANTHROPIC_API_KEY_3, ANTHROPIC_API_KEY_4, ANTHROPIC_API_KEY_5, ANTHROPIC_API_KEY_6, ANTHROPIC_API_KEY_7, user_states
from utils import run_loading_animation, smart_send_text_unified, grouped_reports_to_string, get_username_from_chat
from db_handler.db import fetch_prompts_for_scenario_reporttype_building, fetch_prompt_by_name
from datamodels import mapping_report_type_names, mapping_building_names, REPORT_MAPPING, CLASSIFY_DESIGN, CLASSIFY_INTERVIEW
from menus import send_main_menu
from markups import interview_menu_markup, design_menu_markup, main_menu_markup, make_dialog_markup
from menu_manager import send_menu
from message_tracker import track_and_send
from analysis import analyze_methodology, classify_query, extract_from_chunk_parallel, aggregate_citations, classify_report_type, generate_db_answer, extract_from_chunk_parallel_async
from storage import save_user_input_to_db, build_reports_grouped, create_db_in_memory
from query_expander import expand_query
# Router Agent –º–æ–¥—É–ª–∏ –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞ –∏–Ω–¥–µ–∫—Å–∞
from relevance_evaluator import evaluate_report_relevance, load_report_descriptions
from index_selector import select_most_relevant_index, INDEX_MAPPING, INDEX_DISPLAY_NAMES, get_top_relevant_indices, format_index_recommendations
from question_enhancer import enhance_question_for_index

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è UI –∏ –∏–Ω–¥–µ–∫—Å–æ–≤
MIN_RELEVANCE_SCORE = 10.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
INDEX_SURVEY_REPORTS = "–û—Ç—á–µ—Ç—ã –ø–æ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é"  # –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ 4 –º–µ—Å—Ç–∞—Ö

# SonarCloud fix: duplicated literals - –≤—ã–Ω–µ—Å–µ–Ω—ã –≤ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
CATEGORY_INTERVIEW = "–ò–Ω—Ç–µ—Ä–≤—å—é"
CATEGORY_DESIGN_SOURCES = "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"
CATEGORY_FINAL_REPORTS = "–ò—Ç–æ–≥–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã"
CATEGORY_DESIGN_REPORTS = "–û—Ç—á–µ—Ç—ã –ø–æ –¥–∏–∑–∞–π–Ω—É"

# –ú–∞–ø–ø–∏–Ω–≥ –∏–º–µ–Ω –∏–Ω–¥–µ–∫—Å–æ–≤ Router Agent -> rags
# Router Agent –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–º–µ–Ω–∞ (Dizayn, Intervyu),
# –∞ rags –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä—É—Å—Å–∫–∏–µ –∏–º–µ–Ω–∞ (–î–∏–∑–∞–π–Ω, –ò–Ω—Ç–µ—Ä–≤—å—é)
ROUTER_TO_RAG_MAPPING: dict[str, str] = {
    "Dizayn": "–î–∏–∑–∞–π–Ω",
    "Intervyu": CATEGORY_INTERVIEW,
    "Iskhodniki_dizayn": "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –¥–∏–∑–∞–π–Ω",
    "Iskhodniki_obsledovanie": CATEGORY_DESIGN_SOURCES,
    "Itogovye_otchety": CATEGORY_FINAL_REPORTS,
    "Otchety_po_dizaynu": CATEGORY_DESIGN_REPORTS,
    "Otchety_po_obsledovaniyu": INDEX_SURVEY_REPORTS
}


def load_market_research_files(rag_name: str) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (60 –ø–∞–ø–æ–∫ –æ—Ç–µ–ª–µ–π)
    –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è RAG –∏–Ω–¥–µ–∫—Å–∞.

    –§—É–Ω–∫—Ü–∏—è —Å–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å 60 –æ—Ç–µ–ª—è–º–∏ –†–§, –∏–∑–≤–ª–µ–∫–∞–µ—Ç TXT –∏ DOCX —Ñ–∞–π–ª—ã —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–Ω–¥–µ–∫—Å–∞,
    –ø–∞—Ä—Å–∏—Ç –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è.

    Args:
        rag_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏. –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:
            - "–û—Ç—á–µ—Ç—ã –ø–æ –¥–∏–∑–∞–π–Ω—É" - TXT –æ—Ç—á–µ—Ç—ã –∏–∑ –ø–∞–ø–∫–∏ "–î–∏–∑–∞–π–Ω –æ—Ç—á–µ—Ç—ã"
            - "–û—Ç—á–µ—Ç—ã –ø–æ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é" - TXT –æ—Ç—á–µ—Ç—ã –∏–∑ –ø–∞–ø–∫–∏ "–û–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç—ã"
            - "–ò—Ç–æ–≥–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã" - TXT –æ—Ç—á–µ—Ç—ã –∏–∑ –ø–∞–ø–∫–∏ "–ò—Ç–æ–≥–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã"
            - "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –¥–∏–∑–∞–π–Ω" - DOCX —Ñ–∞–π–ª—ã —Å "–∞—É–¥–∏—Ç" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (–ø–æ–¥–ø–∞–ø–∫–∞ "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏")
            - "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ" - DOCX —Ñ–∞–π–ª—ã —Å "–æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (–ø–æ–¥–ø–∞–ø–∫–∞ "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏")

    Returns:
        str: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
            # –û—Ç–µ–ª—å: <hotel_name>
            # –§–∞–π–ª: <filename>

            <file_text>

            ================================================================================

    Raises:
        FileNotFoundError: –ï—Å–ª–∏ –±–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è MarketResearch/RF –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        ValueError: –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ rag_name

    Examples:
        –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å: C:/Users/l0934/Projects/VoxPersona/rag_indices/MarketResearch/RF/
        –°–µ—Ä–≤–µ—Ä–Ω—ã–π –ø—É—Ç—å: /app/rag_indices/MarketResearch/RF/

        >>> content = load_market_research_files("–û—Ç—á–µ—Ç—ã –ø–æ –¥–∏–∑–∞–π–Ω—É")
        >>> print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(content)} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ –æ—Ç—á–µ—Ç–æ–≤ –ø–æ –¥–∏–∑–∞–π–Ω—É")

    Notes:
        - –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç .txt —Ñ–∞–π–ª—ã (–æ—Ç—á–µ—Ç—ã) –∏ .docx —Ñ–∞–π–ª—ã (–∏—Å—Ö–æ–¥–Ω–∏–∫–∏)
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫—Ä–æ—Å—Å–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–π pathlib.Path
        - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π/—Å–µ—Ä–≤–µ—Ä–Ω—ã–π —Ä–µ–∂–∏–º
        - –ü—Ä–æ–ø—É—Å–∫–∞–µ—Ç —Ñ–∞–π–ª—ã —Å –æ—à–∏–±–∫–∞–º–∏ —á—Ç–µ–Ω–∏—è (–ª–æ–≥–∏—Ä—É–µ—Ç, –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å)
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –∏ –Ω–∞–ª–∏—á–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """

    # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ –ø—É—Ç–∏ (–ª–æ–∫–∞–ª—å–Ω–æ vs —Å–µ—Ä–≤–µ—Ä)
    # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è /app/rag_indices –ò —ç—Ç–æ –Ω–µ Windows
    if os.path.exists("/app/rag_indices/MarketResearch") and os.name != 'nt':
        base_path = Path("/app/rag_indices/MarketResearch/RF")
        logging.info("üåê –†–µ–∂–∏–º: –°–ï–†–í–ï–† - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Ç—å /app/rag_indices")
    else:
        base_path = Path("C:/Users/l0934/Projects/VoxPersona/rag_indices/MarketResearch/RF")
        logging.info("üíª –†–µ–∂–∏–º: –õ–û–ö–ê–õ–¨–ù–û - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Ç—å C:/Users/l0934/Projects/VoxPersona")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –±–∞–∑–æ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    if not base_path.exists():
        error_msg = f"‚ùå –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {base_path}"
        logging.error(error_msg)
        raise FileNotFoundError(error_msg)

    logging.info(f"üìÇ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–∞–π–¥–µ–Ω–∞: {base_path}")

    # –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–∞ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞
    rag_configs = {
        CATEGORY_DESIGN_REPORTS: {
            "folder_pattern": "–î–∏–∑–∞–π–Ω –æ—Ç—á–µ—Ç—ã",
            "file_pattern": None,
            "search_type": "folder"
        },
        INDEX_SURVEY_REPORTS: {
            "folder_pattern": "–û–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç—ã",
            "file_pattern": None,
            "search_type": "folder"
        },
        CATEGORY_FINAL_REPORTS: {
            "folder_pattern": "–ò—Ç–æ–≥–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã",
            "file_pattern": None,
            "search_type": "folder"
        },
        "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –¥–∏–∑–∞–π–Ω": {
            "folder_pattern": None,
            "file_pattern": "–∞—É–¥–∏—Ç",  # –†–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
            "search_type": "file"
        },
        CATEGORY_DESIGN_SOURCES: {
            "folder_pattern": None,
            "file_pattern": "–æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ",  # –†–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
            "search_type": "file"
        },
    }

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    if rag_name not in rag_configs:
        available_rags = ', '.join(rag_configs.keys())
        error_msg = f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π RAG –∏–Ω–¥–µ–∫—Å: '{rag_name}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {available_rags}"
        logging.error(error_msg)
        raise ValueError(error_msg)

    config = rag_configs[rag_name]
    logging.info(f"üîç –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è '{rag_name}': {config}")

    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–∞–ø–æ–∫ –æ—Ç–µ–ª–µ–π (60 –ø–∞–ø–æ–∫)
    hotel_folders = [folder for folder in base_path.iterdir() if folder.is_dir()]
    logging.info(f"üè® –ù–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫ –æ—Ç–µ–ª–µ–π: {len(hotel_folders)}")

    if not hotel_folders:
        logging.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏ –æ—Ç–µ–ª—è –≤ {base_path}")
        return ""

    # –ö–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤
    all_texts = []
    files_processed = 0
    files_skipped = 0

    # –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –≤—Å–µ–º –ø–∞–ø–∫–∞–º –æ—Ç–µ–ª–µ–π
    for hotel_folder in hotel_folders:
        hotel_name = hotel_folder.name
        logging.debug(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–µ–ª—è: {hotel_name}")

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–∞
        files_to_process = []

        if config["search_type"] == "folder":
            # –ü–æ–∏—Å–∫ –ø–æ –ø–∞–ø–∫–µ (–û—Ç—á–µ—Ç—ã –ø–æ –¥–∏–∑–∞–π–Ω—É, –û–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—é, –ò—Ç–æ–≥–æ–≤—ã–µ)
            target_folder = hotel_folder / config["folder_pattern"]

            if not target_folder.exists():
                logging.debug(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ {hotel_name}: –ø–∞–ø–∫–∞ '{config['folder_pattern']}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                files_skipped += 1
                continue

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ TXT —Ñ–∞–π–ª—ã –∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–∞–ø–∫–∏ (–æ—Ç—á–µ—Ç—ã —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ TXT —Ñ–æ—Ä–º–∞—Ç–µ)
            files_to_process = list(target_folder.glob("*.txt"))

        elif config["search_type"] == "file":
            # –ü–æ–∏—Å–∫ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞ (–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –¥–∏–∑–∞–π–Ω/–æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ)
            pattern = config["file_pattern"].lower()

            # –ü–æ–∏—Å–∫ –≤ –ø–æ–¥–ø–∞–ø–∫–µ "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏/" (–Ω–µ –≤ –∫–æ—Ä–Ω–µ –æ—Ç–µ–ª—è!)
            sources_folder = hotel_folder / "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏"

            if not sources_folder.exists():
                logging.debug(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ {hotel_name}: –ø–∞–ø–∫–∞ '–ò—Å—Ö–æ–¥–Ω–∏–∫–∏' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                files_skipped += 1
                continue

            # –ü–æ–∏—Å–∫ DOCX —Ñ–∞–π–ª–æ–≤ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –≤ –ø–æ–¥–ø–∞–ø–∫–µ –ò—Å—Ö–æ–¥–Ω–∏–∫–∏
            files_to_process = [
                file_path for file_path in sources_folder.glob("*.docx")
                if pattern in file_path.name.lower()
            ]

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (TXT –∏–ª–∏ DOCX)
        if not files_to_process:
            logging.debug(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ {hotel_name}: —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            files_skipped += 1
            continue

        for file_path in files_to_process:
            try:
                # –ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                if file_path.suffix == '.docx':
                    # DOCX —Ñ–∞–π–ª—ã (–∏—Å—Ö–æ–¥–Ω–∏–∫–∏) - –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ python-docx
                    doc = Document(file_path)
                    paragraphs = [para.text for para in doc.paragraphs if para.text.strip()]
                    file_text = "\n".join(paragraphs)
                elif file_path.suffix == '.txt':
                    # TXT —Ñ–∞–π–ª—ã (–æ—Ç—á–µ—Ç—ã) - —á—Ç–µ–Ω–∏–µ –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_text = f.read()
                else:
                    # –ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–π–ª–æ–≤ —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
                    logging.debug(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ —Ñ–∞–π–ª–∞ —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º: {file_path.name}")
                    continue

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ—Ç—É
                if not file_text.strip():
                    logging.debug(f"‚ö†Ô∏è –§–∞–π–ª –ø—É—Å—Ç: {file_path.name} ({hotel_name})")
                    continue

                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                formatted_text = (
                    f"# –û—Ç–µ–ª—å: {hotel_name}\n"
                    f"# –§–∞–π–ª: {file_path.name}\n\n"
                    f"{file_text}\n\n"
                    f"{'='*80}\n\n"
                )

                all_texts.append(formatted_text)
                files_processed += 1
                logging.debug(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª: {file_path.name} ({hotel_name}), —Å–∏–º–≤–æ–ª–æ–≤: {len(file_text)}")

            except Exception as e:
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ –±–µ–∑ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path.name} ({hotel_name}): {e}")
                continue

    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤
    combined_content = "".join(all_texts)

    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    logging.info(
        f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è '{rag_name}': "
        f"–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {files_processed}, "
        f"–ø—Ä–æ–ø—É—â–µ–Ω–æ –æ—Ç–µ–ª–µ–π: {files_skipped}, "
        f"–∏—Ç–æ–≥–æ–≤—ã–π –æ–±—ä–µ–º: {len(combined_content)} —Å–∏–º–≤–æ–ª–æ–≤"
    )

    if not combined_content:
        logging.warning(f"‚ö†Ô∏è –î–ª—è –∏–Ω–¥–µ–∫—Å–∞ '{rag_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞!")

    return combined_content


def load_all_report_descriptions() -> dict[str, str]:
    """
    DEPRECATED: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ load_report_descriptions() –∏–∑ relevance_evaluator.py –≤–º–µ—Å—Ç–æ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏.

    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ö–û–†–û–¢–ö–ò–ï –∏–º–µ–Ω–∞ –æ—Ç—á–µ—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ"),
    –∫–æ—Ç–æ—Ä—ã–µ –ù–ï —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç REPORT_TO_INDEX_MAPPING –∏ INDEX_MAPPING.

    load_report_descriptions() –∏–∑ relevance_evaluator.py –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ü–û–õ–ù–´–ï –∏–º–µ–Ω–∞
    (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ì–ª–∞–≤–Ω–∞—è_–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"),
    –∫–æ—Ç–æ—Ä—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –º–∞–ø–ø–∏–Ω–≥–∞–º.

    ---

    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ 22 —Ñ–∞–π–ª–∞ –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ Description/Report content/.

    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é Description/Report content/, —á–∏—Ç–∞–µ—Ç –≤—Å–µ .md —Ñ–∞–π–ª—ã
    –∏ —Å–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –∏–º–µ–Ω–∞–º–∏ –æ—Ç—á–µ—Ç–æ–≤ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–ª—é—á–µ–π.

    Returns:
        dict[str, str]: –°–ª–æ–≤–∞—Ä—å {–∫–æ—Ä–æ—Ç–∫–æ–µ_–∏–º—è_–æ—Ç—á–µ—Ç–∞: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ_—Ñ–∞–π–ª–∞}
        –ü—Ä–∏–º–µ—Ä: {
            "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π_–æ—Ç—á–µ—Ç_–∞—É–¥–∏—Ç–∞": "# –û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞...",
            "–û–±—â–∏–µ_—Ñ–∞–∫—Ç–æ—Ä—ã": "# –û–±—â–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã...",
            ...
        }

    Raises:
        FileNotFoundError: –ï—Å–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è Description/Report content/ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        RuntimeError: –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–µ 22 —Ñ–∞–π–ª–∞ (–æ–∂–∏–¥–∞–µ–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)

    Example:
        >>> descriptions = load_all_report_descriptions()
        >>> len(descriptions)
        22
        >>> "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ" in descriptions
        True
    """
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞ (–ª–æ–∫–∞–ª—å–Ω–æ vs —Å–µ—Ä–≤–µ—Ä)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É: –Ω–∞ Windows –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å
    import sys
    is_windows = sys.platform == "win32"
    server_path = Path("/home/voxpersona_user/VoxPersona")

    if not is_windows and server_path.exists():
        base_path = server_path
        logging.info("üåê –°–µ—Ä–≤–µ—Ä: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç—å /home/voxpersona_user/VoxPersona")
    else:
        base_path = Path(__file__).parent.parent
        logging.info(f"üíª –õ–æ–∫–∞–ª—å–Ω–æ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç—å {base_path}")

    # –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –æ—Ç—á–µ—Ç–æ–≤
    descriptions_dir = base_path / "Description" / "Report content"

    if not descriptions_dir.exists():
        error_msg = f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –æ—Ç—á–µ—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {descriptions_dir}"
        logging.error(f"‚ùå {error_msg}")
        raise FileNotFoundError(error_msg)

    logging.info(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç—á–µ—Ç–æ–≤ –∏–∑: {descriptions_dir}")

    # –ú–∞–ø–ø–∏–Ω–≥ –¥–ª–∏–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π ‚Üí –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–º–µ–Ω–∞
    name_mappings = {
        "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ",
        "–û—â—É—â–µ–Ω–∏—è –æ—Ç –æ—Ç–µ–ª—è": "–û—â—É—â–µ–Ω–∏—è",
        "–ó–∞–ø–æ–ª–Ω—è–µ–º–æ—Å—Ç—å_–∏_–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ": "–ó–∞–ø–æ–ª–Ω—è–µ–º–æ—Å—Ç—å",
        "–ò—Ç–æ–≥–æ–≤—ã–π_–æ—Ç—á–µ—Ç": "–ò—Ç–æ–≥–æ–≤—ã–π",
        "–û—Ç–¥—ã—Ö_–∏_–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ": "–û—Ç–¥—ã—Ö",
        "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏_–ø–æ_—É–ª—É—á—à–µ–Ω–∏—é": "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏",
        "–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –¥–∏–∑–∞–π–Ω–∞": "–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã",
        "–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏_–¥–∏–∑–∞–π–Ω–∞": "–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏",
        "–û–∂–∏–¥–∞–Ω–∏—è_–∏_—Ä–µ–∞–ª—å–Ω–æ—Å—Ç—å": "–û–∂–∏–¥–∞–Ω–∏—è",
        "–ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è_–∫–æ–Ω—Ü–µ–ø—Ü–∏–∏_–∏_–¥–∏–∑–∞–π–Ω–∞": "–ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è",
        "–í–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω–æ—Å—Ç—å_–≥–æ—Å—Ç–∏–Ω–∏—á–Ω–æ–≥–æ_—Ö–æ–∑—è–π—Å—Ç–≤–∞": "–í–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω–æ—Å—Ç—å",
        "–û–±—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ_–≥–æ—Å—Ç–∏–Ω–∏—á–Ω–æ–≥–æ_—Ö–æ–∑—è–π—Å—Ç–≤–∞": "–û–±—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ",
        "–ö–∞—á–µ—Å—Ç–≤–æ_–∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã": "–ö–∞—á–µ—Å—Ç–≤–æ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã",
    }

    def extract_short_name(filename: str) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –æ—Ç—á–µ—Ç–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞.

        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ_–æ—Ç—á–µ—Ç–æ–≤_–ò—Ç–æ–≥–æ–≤—ã–π_–æ—Ç—á–µ—Ç.md")

        Returns:
            str: –ö–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ò—Ç–æ–≥–æ–≤—ã–π")
        """
        # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .md
        name = filename.replace(".md", "")

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã (—Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞–ø–∏—Å–∞–Ω–∏—è)
        prefixes = [
            "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ_–æ—Ç—á–µ—Ç–æ–≤_",
            "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤_",
            "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ ",
            "–ì–ª–∞–≤–Ω–∞—è_"
        ]
        for prefix in prefixes:
            name = name.replace(prefix, "")

        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
        for long_name, short_name in name_mappings.items():
            if long_name in name:
                return short_name

        return name

    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω–∏–π
    descriptions = {}

    # –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –æ–±—Ö–æ–¥ –≤—Å–µ—Ö .md —Ñ–∞–π–ª–æ–≤
    md_files = list(descriptions_dir.rglob("*.md"))
    logging.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(md_files)} .md —Ñ–∞–π–ª–æ–≤")

    for file_path in md_files:
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è
            short_name = extract_short_name(file_path.name)

            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
            descriptions[short_name] = content
            logging.debug(f"  ‚úÖ {file_path.name} ‚Üí '{short_name}' ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")

        except Exception as e:
            logging.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file_path.name}: {e}")
            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            continue

    # –í–∞–ª–∏–¥–∞—Ü–∏—è: –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–æ–≤–Ω–æ 22 —Ñ–∞–π–ª–∞
    expected_count = 22
    actual_count = len(descriptions)

    if actual_count != expected_count:
        error_msg = (
            f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {actual_count} –æ–ø–∏—Å–∞–Ω–∏–π, –æ–∂–∏–¥–∞–ª–æ—Å—å {expected_count}. "
            f"–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ: {sorted(descriptions.keys())}"
        )
        logging.error(f"‚ùå {error_msg}")
        raise RuntimeError(error_msg)

    logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {actual_count} –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç—á–µ—Ç–æ–≤")
    logging.debug(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã: {sorted(descriptions.keys())}")

    return descriptions


def init_rags(existing_rags: dict | None = None) -> dict:
    rags = existing_rags.copy() if existing_rags else {}

    # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∫–∏–µ –∏–Ω–¥–µ–∫—Å—ã —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
    if rags:
        logging.info(f"üì¶ –ü–æ–ª—É—á–µ–Ω—ã pre-loaded RAG –∏–Ω–¥–µ–∫—Å—ã: {list(rags.keys())}")
    else:
        logging.info("üì¶ Pre-loaded RAG –∏–Ω–¥–µ–∫—Å–æ–≤ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –≤—Å–µ —Å –Ω—É–ª—è")

    # === –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø: 9 —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö + 5 –Ω–æ–≤—ã—Ö –ú–ò –∏–Ω–¥–µ–∫—Å–æ–≤ ===
    rag_configs = [
        # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã (PostgreSQL)
        (CATEGORY_INTERVIEW, None, None),
        ("–î–∏–∑–∞–π–Ω", None, None),
        (CATEGORY_INTERVIEW, "–û—Ü–µ–Ω–∫–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é", None),
        (CATEGORY_INTERVIEW, "–û—Ç—á–µ—Ç –æ —Å–≤—è–∑–∫–∞—Ö", None),
        (CATEGORY_INTERVIEW, "–û–±—â–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã", None),
        (CATEGORY_INTERVIEW, "–§–∞–∫—Ç–æ—Ä—ã –≤ —ç—Ç–æ–º –∑–∞–≤–µ–¥–µ–Ω–∏–∏", None),
        ("–î–∏–∑–∞–π–Ω", "–û—Ü–µ–Ω–∫–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∞—É–¥–∏—Ç–∞", None),
        ("–î–∏–∑–∞–π–Ω", "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º–µ –∞—É–¥–∏—Ç–∞", None),
        ("–î–∏–∑–∞–π–Ω", "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç –∞—É–¥–∏—Ç–∞", None),

        # === –ù–û–í–´–ï –ò–ù–î–ï–ö–°–´ –ú–ò (–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ) ===
        (None, CATEGORY_DESIGN_REPORTS, "market_research"),
        (None, INDEX_SURVEY_REPORTS, "market_research"),
        (None, CATEGORY_FINAL_REPORTS, "market_research"),
        (None, "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –¥–∏–∑–∞–π–Ω", "market_research"),
        (None, CATEGORY_DESIGN_SOURCES, "market_research"),
    ]

    for config in rag_configs:
        # === –ò–ó–ú–ï–ù–ï–ù–ò–ï: –¢–µ–ø–µ—Ä—å —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –≤—Å–µ 3 —ç–ª–µ–º–µ–Ω—Ç–∞ tuple ===
        scenario_name, report_type, source_type = config

        try:
            rag_name = report_type if report_type else scenario_name
            if rag_name in rags:
                logging.info(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ {rag_name}: —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω —Å –¥–∏—Å–∫–∞")
                continue
            logging.info(f"üèóÔ∏è  –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ {rag_name}...")

            # === –í–´–ë–û–† –ò–°–¢–û–ß–ù–ò–ö–ê –î–ê–ù–ù–´–• ===
            if source_type == "market_research":
                # –ú–ò –∏–Ω–¥–µ–∫—Å—ã: –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (60 –æ—Ç–µ–ª–µ–π)
                content_str = load_market_research_files(rag_name)
                if not content_str:
                    logging.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ {rag_name}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ú–ò")
                    continue
            else:
                # –°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã: –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ PostgreSQL
                # ‚úÖ –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ú–ï–¢–û–î–û–õ–û–ì–ò–ß–ï–°–ö–ò–• –û–¢–ß–ï–¢–û–í:
                # –î–ª—è –∏–Ω–¥–µ–∫—Å–æ–≤ "–ò–Ω—Ç–µ—Ä–≤—å—é" –∏ "–î–∏–∑–∞–π–Ω" –∏—Å–∫–ª—é—á–∞–µ–º –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Ç—á–µ—Ç—ã
                # ‚úÖ –ü–†–û–ë–õ–ï–ú–ê #5: –î–æ–±–∞–≤–ª–µ–Ω type hint list[str] | None
                exclude_types: list[str] | None = None

                if rag_name == CATEGORY_INTERVIEW:
                    exclude_types = ["–û—Ü–µ–Ω–∫–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é"]
                    logging.info(f"üìã –ò–Ω–¥–µ–∫—Å '–ò–Ω—Ç–µ—Ä–≤—å—é': –∏—Å–∫–ª—é—á–∞–µ–º —Ç–∏–ø—ã {exclude_types}")
                elif rag_name == "–î–∏–∑–∞–π–Ω":
                    exclude_types = [
                        "–û—Ü–µ–Ω–∫–∞ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏ –∞—É–¥–∏—Ç–∞",
                        "–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º–µ –∞—É–¥–∏—Ç–∞"
                    ]
                    logging.info(f"üìã –ò–Ω–¥–µ–∫—Å '–î–∏–∑–∞–π–Ω': –∏—Å–∫–ª—é—á–∞–µ–º —Ç–∏–ø—ã {exclude_types}")

                content = build_reports_grouped(
                    scenario_name=scenario_name,
                    report_type=report_type,
                    exclude_report_types=exclude_types  # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                )
                content_str = grouped_reports_to_string(content)
            # === –ö–û–ù–ï–¶ –í–´–ë–û–†–ê –ò–°–¢–û–ß–ù–ò–ö–ê ===

            # === –†–ê–°–®–ò–†–ï–ù–ù–û–ï –£–°–õ–û–í–ò–ï: 7 FAISS –∏–Ω–¥–µ–∫—Å–æ–≤ (2 —Å—Ç–∞—Ä—ã—Ö + 5 –Ω–æ–≤—ã—Ö –ú–ò) ===
            if rag_name in [CATEGORY_INTERVIEW, "–î–∏–∑–∞–π–Ω", CATEGORY_DESIGN_REPORTS, INDEX_SURVEY_REPORTS, CATEGORY_FINAL_REPORTS, "–ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –¥–∏–∑–∞–π–Ω", CATEGORY_DESIGN_SOURCES]:
                rag_db = create_db_in_memory(content_str)
                rags[rag_name] = rag_db
                logging.info(f"‚úÖ FAISS –∏–Ω–¥–µ–∫—Å –¥–ª—è {rag_name} —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            else:
                rags[rag_name] = content_str
                logging.info(f"‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è {rag_name} —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–∞–≥–∞ –¥–ª—è {config}: {e}")
            continue  # –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å–æ —Å–ª–µ–¥—É—é—â–∏–º –∏–Ω–¥–µ–∫—Å–æ–º –≤–º–µ—Å—Ç–æ return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –±—ã–ª–∏ –ª–∏ —Å–æ–∑–¥–∞–Ω—ã —Ö–æ—Ç—è –±—ã –∫–∞–∫–∏–µ-—Ç–æ –∏–Ω–¥–µ–∫—Å—ã
    if not rags:
        logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ RAG –∏–Ω–¥–µ–∫—Å–∞!")

    return rags

def run_fast_search(text: str, rag) -> str:
    logging.info("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞")
    answer = generate_db_answer(text, rag)
    return answer

def run_deep_search(content: str, text: str, chat_id: int, app: Client, category: str) -> str:
    api_keys = [ANTHROPIC_API_KEY, ANTHROPIC_API_KEY_2, ANTHROPIC_API_KEY_3, ANTHROPIC_API_KEY_4, ANTHROPIC_API_KEY_5, ANTHROPIC_API_KEY_6, ANTHROPIC_API_KEY_7]

    chunks = re.split(r'^# –ß–∞–Ω–∫ transcription_id \d+', content, flags=re.MULTILINE)
    chunks = [chunk.strip() for chunk in chunks if chunk.strip()]

    logging.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è {category}")

    if not chunks:
        app.send_message(chat_id, f"–û—à–∏–±–∫–∞: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –æ—Ç—á–µ—Ç—ã –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'")
        return

    extract_prompt = fetch_prompt_by_name(prompt_name="prompt_extract")
    aggregation_prompt = fetch_prompt_by_name(prompt_name="prompt_agg")

    # === –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ extract_from_chunk_parallel_async ===
    async def main():
        async with aiohttp.ClientSession() as session:
            return await extract_from_chunk_parallel_async(
                text=text,
                chunks=chunks,
                extract_prompt=extract_prompt,
                api_keys=api_keys,
                session=session
            )

    try:
        loop = asyncio.get_event_loop()
        results = loop.run_until_complete(main())
    except RuntimeError as e:
        results = asyncio.run(main())

    citations = [r for r in results if r != "##not_found##" and not r.startswith("[ERROR]")]

    if citations:
        aggregated_answer = aggregate_citations(
            text=text,
            citations=citations,
            aggregation_prompt=aggregation_prompt
        )
    else:
        aggregated_answer = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ—Ç—á–µ—Ç–∞—Ö."

    return aggregated_answer

async def show_expanded_query_menu(
    chat_id: int,
    app: Client,
    original: str,
    expanded: str,
    conversation_id: str,
    deep_search: bool,
    refine_count: int = 0,
    selected_index: str | None = None,
    top_indices: list | None = None  # –ù–û–í–´–ô –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π Router Agent
):
    """
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ —É–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

    –§–ê–ó–ê 4: –û–±–Ω–æ–≤–ª–µ–Ω–æ - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç make_query_expansion_markup()
    –§–ê–ó–ê 5: –î–æ–±–∞–≤–ª–µ–Ω—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–Ω–¥–µ–∫—Å–æ–≤ –æ—Ç Router Agent

    Args:
        chat_id: ID —á–∞—Ç–∞ Telegram
        app: Pyrogram –∫–ª–∏–µ–Ω—Ç
        original: –ò—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        expanded: –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å
        conversation_id: ID –º—É–ª—å—Ç–∏—á–∞—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å None)
        deep_search: True = –≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ, False = –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
        refine_count: –¢–µ–∫—É—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ —É—Ç–æ—á–Ω–µ–Ω–∏—è (–∑–∞—â–∏—Ç–∞ –æ—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è)
        selected_index: –í—Ä—É—á–Ω—É—é –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å (None = –∞–≤—Ç–æ–≤—ã–±–æ—Ä Router Agent)
        top_indices: –°–ø–∏—Å–æ–∫ —Ç–æ–ø-K —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –æ—Ç Router Agent (None = –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å)
                    –§–æ—Ä–º–∞—Ç: [(index_name, score), ...]
    """
    # FIX (2025-11-09): –ó–∞—â–∏—Ç–∞ –æ—Ç MESSAGE_TOO_LONG
    # –ó–ê–ß–ï–ú: Telegram –ª–∏–º–∏—Ç 4096 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    # –ü–û–ß–ï–ú–£ 3900: –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç —Å –∑–∞–ø–∞—Å–æ–º –¥–ª—è markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –∫–Ω–æ–ø–æ–∫ (4096 - 196 overhead)
    # TODO (P2): –í –±—É–¥—É—â–µ–º –¥–æ–±–∞–≤–∏—Ç—å –∫–Ω–æ–ø–∫—É "–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é" ‚Üí –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ñ–∞–π–ª–æ–º –ø—Ä–∏ –æ–±—Ä–µ–∑–∫–µ
    # –°–≤—è–∑—å: TASKS/2025-11-09_query_expansion_errors/inspection.md (–†–ï–®–ï–ù–ò–ï 3 - –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥)

    MAX_TELEGRAM_TEXT = 3900  # Telegram limit 4096 - overhead –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    expanded_display = expanded

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
    if len(expanded) > MAX_TELEGRAM_TEXT:
        logger = logging.getLogger(__name__)
        logger.warning(
            f"[Query Expansion] Expanded question too long: {len(expanded)} chars, "
            f"truncating to {MAX_TELEGRAM_TEXT} chars. Chat ID: {chat_id}"
        )
        # –û–±—Ä–µ–∑–∞–µ–º —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        expanded_display = (
            expanded[:MAX_TELEGRAM_TEXT] +
            "\n\n‚ö†Ô∏è _(–í–æ–ø—Ä–æ—Å –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª–∏–Ω—ã Telegram)_"
        )

    # === –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–Ω–¥–µ–∫—Å–∞—Ö ===
    # –§–ê–ó–ê 5: –î–æ–±–∞–≤–ª–µ–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π Router Agent
    index_info = ""

    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–Ω–¥–µ–∫—Å–∞–º –æ—Ç Router Agent - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö
    # –í–ê–ñ–ù–û: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è UI, –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ RAG –ø–æ–∏—Å–∫
    if top_indices:
        recommendations_text = format_index_recommendations(top_indices)
        index_info = f"{recommendations_text}\n\n"
        logging.info(f"[Query Expansion] –ü–æ–∫–∞–∑–∞–Ω—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–Ω–¥–µ–∫—Å–æ–≤: {len(top_indices)} —à—Ç")

    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—Ä—É—á–Ω—É—é –≤—ã–±—Ä–∞–ª –∏–Ω–¥–µ–∫—Å - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ
    if selected_index:
        index_display_name = INDEX_DISPLAY_NAMES.get(selected_index, selected_index)
        index_info += f"üéØ **–í—ã–±—Ä–∞–Ω –∏–Ω–¥–µ–∫—Å:** {index_display_name}\n\n"

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º (–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ info_message - –Ω–µ —É–¥–∞–ª—è–µ—Ç—Å—è)
    info_text = (
        f"üìù **–í–∞—à –≤–æ–ø—Ä–æ—Å:**\n"
        f"_{original}_\n\n"
        f"üîç **–£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å:**\n"
        f"*{expanded_display}*\n\n"
        f"{index_info}"
    )

    # –¢–µ–∫—Å—Ç –¥–ª—è –º–µ–Ω—é —Å –∫–Ω–æ–ø–∫–∞–º–∏ (–∫–æ—Ä–æ—Ç–∫–∏–π, —É–¥–∞–ª—è–µ—Ç—Å—è –ø—Ä–∏ —Å–º–µ–Ω–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    menu_text = f"–û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å –≤ {'–≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ' if deep_search else '–±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫'}?"


    # –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω–∞—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ —Å hash –∏ user_states
    from markups import make_query_expansion_markup
    markup = make_query_expansion_markup(
        original_question=original,
        expanded_question=expanded,  # –ü–µ—Ä–µ–¥–∞–µ–º –ü–û–õ–ù–´–ô –≤–æ–ø—Ä–æ—Å –≤ callback_data
        conversation_id=conversation_id or "",
        deep_search=deep_search,
        refine_count=refine_count,
        selected_index=selected_index,
        top_indices=top_indices  # –ó–ê–î–ê–ß–ê 2.3: –ü–µ—Ä–µ–¥–∞–µ–º —Ç–æ–ø-3 –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ user_states
    )

    # –®–ê–ì 3.3: –†–∞–∑–¥–µ–ª—è–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –Ω–∞ info_message –∏ menu
    # –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É: —Ç–µ–∫—Å—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º –æ—Å—Ç–∞–µ—Ç—Å—è –≤–∏–¥–∏–º—ã–º –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –∏–Ω–¥–µ–∫—Å–∞
    # info_message –ù–ï —É–¥–∞–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (–≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç menu)
    try:
        # 1. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –≤–æ–ø—Ä–æ—Å–æ–º –∫–∞–∫ info_message (–Ω–µ —É–¥–∞–ª—è–µ—Ç—Å—è)
        await track_and_send(
            chat_id=chat_id,
            app=app,
            text=info_text,
            message_type="info_message"
        )

        # 2. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ menu
        await send_menu(chat_id, app, menu_text, markup)
    except Exception as e:
        # –ï—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑-–∑–∞ original –≤–æ–ø—Ä–æ—Å–∞) - –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
        if "MESSAGE_TOO_LONG" in str(e):
            logger = logging.getLogger(__name__)
            logger.error(
                f"[Query Expansion] MESSAGE_TOO_LONG even after truncation! "
                f"Text length: {len(info_text)} chars. Chat ID: {chat_id}. "
                f"Sending minimal fallback message."
            )
            # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ-fallback
            fallback_text = (
                f"‚úÖ –í–æ–ø—Ä–æ—Å —É–ª—É—á—à–µ–Ω.\n\n"
                f"–û—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ {'–≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ' if deep_search else '–±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫'}?"
            )
            await send_menu(chat_id, app, fallback_text, markup)
        else:
            # –ü—Ä–æ–∫–∏–¥—ã–≤–∞–µ–º –¥—Ä—É–≥–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –Ω–∞–≤–µ—Ä—Ö
            raise


async def _get_router_recommendations(text: str, chat_id: int) -> list[tuple] | None:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏–Ω–¥–µ–∫—Å–æ–≤ –æ—Ç Router Agent –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI.

    Args:
        text: –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        chat_id: ID —á–∞—Ç–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

    Returns:
        list[tuple] | None: –°–ø–∏—Å–æ–∫ —Ç–æ–ø-K –∏–Ω–¥–µ–∫—Å–æ–≤ [(index_name, score), ...] –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        logging.info("[Router Recommendations] –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –º–µ–Ω—é...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤
        report_descriptions = load_report_descriptions()
        logging.info(f"[Router Recommendations] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(report_descriptions)} –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç—á–µ—Ç–æ–≤")

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –æ—Ç—á–µ—Ç–æ–≤ –∫ —É–ª—É—á—à–µ–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É
        report_relevance = await evaluate_report_relevance(text, report_descriptions)

        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 –∏–Ω–¥–µ–∫—Å–∞ —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        top_indices = get_top_relevant_indices(
            report_relevance,
            top_k=3,
            min_score=MIN_RELEVANCE_SCORE
        )

        logging.info(f"[Router Recommendations] –ü–æ–ª—É—á–µ–Ω–æ {len(top_indices)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π")
        for idx, (index_name, score) in enumerate(top_indices, 1):
            logging.info(f"  {idx}. {index_name}: {score:.1f}%")

        return top_indices

    except Exception as e:
        logging.warning(f"[Router Recommendations] –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        logging.warning("[Router Recommendations] –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–Ω–¥–µ–∫—Å–æ–≤")
        return None


# SonarCloud fix: async without await - —É–±—Ä–∞–Ω async keyword
def _process_manual_index_selection(
    chat_id: int,
    text_to_search: str,
    user_selected_index: str,
    rags: dict,
    top_indices: list[tuple] | None
) -> tuple[str, str, bool]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä—É—á–Ω–æ–π –≤—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.

    Args:
        chat_id: ID —á–∞—Ç–∞
        text_to_search: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        user_selected_index: –í—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏–Ω–¥–µ–∫—Å
        rags: –°–ª–æ–≤–∞—Ä—å RAG –∏–Ω–¥–µ–∫—Å–æ–≤
        top_indices: –¢–æ–ø-K —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞

    Returns:
        tuple[str, str, bool]: (—É–ª—É—á—à–µ–Ω–Ω—ã–π_–∑–∞–ø—Ä–æ—Å, –∏–º—è_—Å—Ü–µ–Ω–∞—Ä–∏—è, —É—Å–ø–µ—Ö)
    """
    logging.info(f"[Manual Index] –û–±–Ω–∞—Ä—É–∂–µ–Ω —Ä—É—á–Ω–æ–π –≤—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–∞: {user_selected_index}")
    logging.info("[Manual Index] –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Router Agent")

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞
        report_descriptions = load_report_descriptions()
        logging.info(f"[Manual Index] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(report_descriptions)} –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç—á–µ—Ç–æ–≤")

        # –£–ª—É—á—à–∞–µ–º –≤–æ–ø—Ä–æ—Å –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Ç–æ–ø-3
        enhanced_question = enhance_question_for_index(
            text_to_search,
            user_selected_index,
            report_descriptions,
            top_indices=top_indices
        )
        logging.info(f"[Manual Index] –í–æ–ø—Ä–æ—Å —É–ª—É—á—à–µ–Ω –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞ '{user_selected_index}'")
        logging.debug(f"[Manual Index] –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å: {enhanced_question[:150]}...")

        # –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞ RAG –∏–Ω–¥–µ–∫—Å
        scenario_name = ROUTER_TO_RAG_MAPPING.get(user_selected_index, user_selected_index)
        logging.info(f"[Manual Index] –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å–∞: '{user_selected_index}' ‚Üí '{scenario_name}'")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ rags
        if scenario_name not in rags:
            raise ValueError(f"–ò–Ω–¥–µ–∫—Å '{scenario_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö rags: {list(rags.keys())}")

        # –û—á–∏—â–∞–µ–º —Ä—É—á–Ω–æ–π –≤—ã–±–æ—Ä –∏–∑ user_states
        user_states[chat_id].pop("selected_index", None)
        logging.info("[Manual Index] –†—É—á–Ω–æ–π –≤—ã–±–æ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∏ –æ—á–∏—â–µ–Ω")

        return enhanced_question, scenario_name, True

    except Exception as e:
        logging.error(f"[Manual Index] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä—É—á–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞: {e}")
        logging.warning("[Manual Index] –û—Ç–∫–∞—Ç –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É Router Agent")
        # –ü—Ä–∏ –æ—à–∏–±–∫–µ - —É–¥–∞–ª—è–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ä—É—á–Ω–æ–π –≤—ã–±–æ—Ä
        user_states.get(chat_id, {}).pop("selected_index", None)
        return text_to_search, "", False


async def _run_router_agent(
    text_to_search: str,
    rags: dict,
    top_indices: list[tuple] | None,
    skip_enhancement: bool = False
) -> tuple[str, str, object, str]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç Router Agent –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞.

    Args:
        text_to_search: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        rags: –°–ª–æ–≤–∞—Ä—å RAG –∏–Ω–¥–µ–∫—Å–æ–≤
        top_indices: –¢–æ–ø-K —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞
        skip_enhancement: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞ (True –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —É–∂–µ —É–ª—É—á—à–µ–Ω —á–µ—Ä–µ–∑ expand_query)

    Returns:
        tuple[str, str, object, str]: (—É–ª—É—á—à–µ–Ω–Ω—ã–π_–∑–∞–ø—Ä–æ—Å, –∏–º—è_—Å—Ü–µ–Ω–∞—Ä–∏—è, rag_–æ–±—ä–µ–∫—Ç, –∫–∞—Ç–µ–≥–æ—Ä–∏—è)

    Raises:
        ValueError: –ü—Ä–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–π —á–µ—Ä–µ–∑ Router Agent –∏ fallback
    """
    try:
        logging.info("[Router] –ó–∞–ø—É—Å–∫ Router Agent –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")

        # –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π –≤—Å–µ—Ö –æ—Ç—á–µ—Ç–æ–≤
        logging.info("[Router] –ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø–∏—Å–∞–Ω–∏–π 22 –æ—Ç—á–µ—Ç–æ–≤...")
        report_descriptions = load_report_descriptions()
        logging.debug(f"[Router] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(report_descriptions)} –æ–ø–∏—Å–∞–Ω–∏–π –æ—Ç—á–µ—Ç–æ–≤")

        # –≠—Ç–∞–ø 2: –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤—Å–µ—Ö –æ—Ç—á–µ—Ç–æ–≤ –∫ –∑–∞–ø—Ä–æ—Å—É
        logging.info(f"[Router] –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç—á–µ—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {text_to_search[:100]}...")
        report_relevance = await evaluate_report_relevance(text_to_search, report_descriptions)
        logging.debug(f"[Router] –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {report_relevance}")

        # –≠—Ç–∞–ø 3: –í—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        logging.info("[Router] –í—ã–±–æ—Ä –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Ü–µ–Ω–æ–∫...")
        selected_index = select_most_relevant_index(report_relevance, INDEX_MAPPING)
        logging.info(f"[Router] –í—ã–±—Ä–∞–Ω –∏–Ω–¥–µ–∫—Å: {selected_index}")

        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3 –∏–Ω–¥–µ–∫—Å–æ–≤ –µ—Å–ª–∏ –Ω–µ –±—ã–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã
        if top_indices is None:
            top_indices = get_top_relevant_indices(
                report_relevance,
                top_k=3,
                min_score=MIN_RELEVANCE_SCORE
            )
            logging.info(f"[Router] –ü–æ–ª—É—á–µ–Ω–æ {len(top_indices)} —Ç–æ–ø-–∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞")

        # –≠—Ç–∞–ø 4: –£–ª—É—á—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —É–∂–µ —É–ª—É—á—à–µ–Ω —á–µ—Ä–µ–∑ expand_query() (–∏–∑–±–µ–≥–∞–µ–º –¥–≤–æ–π–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è)
        if skip_enhancement:
            # –í–æ–ø—Ä–æ—Å —É–∂–µ —É–ª—É—á—à–µ–Ω —á–µ—Ä–µ–∑ expand_query(), –ø–æ–≤—Ç–æ—Ä–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –Ω–µ –Ω—É–∂–Ω–æ
            # –≠—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –¥–≤–æ–π–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞
            logging.info(f"[Router] –ü—Ä–æ–ø—É—Å–∫ enhance_question_for_index (skip_enhancement=True)")
            enhanced_question = text_to_search
        else:
            logging.info(f"[Router] –£–ª—É—á—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞ '{selected_index}'...")
            enhanced_question = enhance_question_for_index(
                text_to_search,
                selected_index,
                report_descriptions,
                top_indices=top_indices
            )
            logging.info(f"[Router] –£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å: {enhanced_question[:150]}...")

        # –ú–∞–ø–ø–∏–Ω–≥ –∏–º–µ–Ω –∏–Ω–¥–µ–∫—Å–æ–≤ Router Agent -> rags
        scenario_name = ROUTER_TO_RAG_MAPPING.get(selected_index, selected_index)
        logging.info(f"[Router] –ú–∞–ø–ø–∏–Ω–≥ –∏–Ω–¥–µ–∫—Å–∞: '{selected_index}' ‚Üí '{scenario_name}'")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ rags
        if scenario_name not in rags:
            raise ValueError(f"–ò–Ω–¥–µ–∫—Å '{scenario_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö rags: {list(rags.keys())}")

        rag = rags[scenario_name]
        category = scenario_name
        logging.info(f"[Router] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è RAG –∏–Ω–¥–µ–∫—Å: {scenario_name}, –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")

        return enhanced_question, scenario_name, rag, category

    except Exception as e:
        # Fallback: –æ—Ç–∫–∞—Ç –∫ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        logging.warning(f"[Router] –û—à–∏–±–∫–∞ Router Agent: {e}")
        logging.warning("[Router] –û—Ç–∫–∞—Ç –∫ fallback-—Å–∏—Å—Ç–µ–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (classify_query)...")

        try:
            category = classify_query(text_to_search)
            logging.info(f"[Fallback] –û–ø—Ä–µ–¥–µ–ª–µ–Ω —Å—Ü–µ–Ω–∞—Ä–∏–π: {category}")

            if category.lower() == "–¥–∏–∑–∞–π–Ω":
                scenario_name = "–î–∏–∑–∞–π–Ω"
            elif category.lower() == "–∏–Ω—Ç–µ—Ä–≤—å—é":
                scenario_name = CATEGORY_INTERVIEW
            else:
                raise ValueError(f"Fallback classify_query –Ω–µ —Å–º–æ–≥ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–π: {category}")

            rag = rags[scenario_name]
            logging.info(f"[Fallback] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è RAG –∏–Ω–¥–µ–∫—Å: {scenario_name}, –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")

            return text_to_search, scenario_name, rag, category

        except Exception as fallback_error:
            logging.error(f"[Fallback] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ fallback-—Å–∏—Å—Ç–µ–º–µ: {fallback_error}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–π –Ω–∏ —á–µ—Ä–µ–∑ Router Agent, –Ω–∏ —á–µ—Ä–µ–∑ fallback: {fallback_error}")


def _validate_search_query(text_to_search: str) -> None:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –∑–∞–ø—Ä–æ—Å –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç UI-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

    Args:
        text_to_search: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    ui_indicators = ["[–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:", "üéØ", "üìä", "**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã:**", "–û—Ç—á–µ—Ç—ã –ø–æ"]
    contains_ui = any(indicator in text_to_search for indicator in ui_indicators)

    if contains_ui:
        logging.warning(f"[RAG Search] –í–ù–ò–ú–ê–ù–ò–ï: text_to_search –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å UI-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é!")
        logging.warning(f"[RAG Search] –≠—Ç–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞")
        logging.warning(f"[RAG Search] –ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {text_to_search[:200]}...")

    logging.info(f"[RAG Search] –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ –ø–æ–∏—Å–∫ (—á–∏—Å—Ç—ã–π –≤–æ–ø—Ä–æ—Å): {text_to_search[:150]}...")
    logging.debug(f"[RAG Search] –ü–æ–ª–Ω—ã–π text_to_search ({len(text_to_search)} —Å–∏–º–≤–æ–ª–æ–≤): {text_to_search}")


async def _save_user_message_to_conversation(
    chat_id: int,
    message_id: int,
    text: str,
    conversation_id: str,
    deep_search: bool
) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞.

    Args:
        chat_id: ID —á–∞—Ç–∞
        message_id: ID —Å–æ–æ–±—â–µ–Ω–∏—è
        text: –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
        conversation_id: ID –¥–∏–∞–ª–æ–≥–∞
        deep_search: –¢–∏–ø –ø–æ–∏—Å–∫–∞ (–≥–ª—É–±–æ–∫–∏–π/–±—ã—Å—Ç—Ä—ã–π)
    """
    from conversation_manager import conversation_manager
    from conversations import ConversationMessage
    from datetime import datetime

    user_message = ConversationMessage(
        timestamp=datetime.now().isoformat(),
        message_id=message_id,
        type="user_question",
        text=text,
        tokens=0,
        sent_as=None,
        file_path=None,
        search_type="deep" if deep_search else "fast"
    )

    conversation_manager.add_message(
        user_id=chat_id,
        conversation_id=conversation_id,
        message=user_message
    )


async def _execute_search_and_send_response(
    chat_id: int,
    app: Client,
    text_to_search: str,
    original_text: str,
    deep_search: bool,
    content: str,
    rag: object,
    category: str,
    username: str,
    conversation_id: str | None
) -> None:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.

    Args:
        chat_id: ID —á–∞—Ç–∞
        app: Pyrogram Client
        text_to_search: –£–ª—É—á—à–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞
        original_text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        deep_search: –¢–∏–ø –ø–æ–∏—Å–∫–∞
        content: –ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ç—á–µ—Ç–æ–≤
        rag: RAG –æ–±—ä–µ–∫—Ç
        category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–∞
        username: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversation_id: ID –¥–∏–∞–ª–æ–≥–∞
    """
    if deep_search:
        await track_and_send(
            chat_id=chat_id,
            app=app,
            text="–ó–∞–ø—É—â–µ–Ω–æ –ì–ª—É–±–æ–∫–æ–µ –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ",
            message_type="status_message"
        )
        logging.info("–ó–∞–ø—É—â–µ–Ω–æ –ì–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ")
        answer = run_deep_search(content, text=text_to_search, chat_id=chat_id, app=app, category=category)
    else:
        # –®–∞–≥ 3.5: –ò–∑–º–µ–Ω–µ–Ω —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—É—Å–∞ –Ω–∞ –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π - —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞
        await track_and_send(
            chat_id=chat_id,
            app=app,
            text="–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é...",
            message_type="status_message"
        )
        logging.info("–ó–∞–ø—É—â–µ–Ω –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫")
        answer = run_fast_search(text=text_to_search, rag=rag)

    formatted_response = f"*–ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–∞:* {category}\n\n{answer}"

    # –£–º–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏ MD —Ñ–∞–π–ª–æ–º
    await smart_send_text_unified(
        text=formatted_response,
        chat_id=chat_id,
        app=app,
        username=username,
        question=original_text,
        search_type="deep" if deep_search else "fast",
        parse_mode=ParseMode.MARKDOWN,
        conversation_id=conversation_id
    )

    max_log_length = 3000
    answer_to_log = answer if len(answer) <= max_log_length else answer[:max_log_length] + "... [–æ–±—Ä–µ–∑–∞–Ω–æ]"
    logging.info(f"–û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω | –û—Ç–≤–µ—Ç: {answer_to_log}")


async def run_dialog_mode(
    message,
    app: Client,
    rags: dict,
    deep_search: bool = False,
    conversation_id: str = None,
    skip_expansion: bool = False,
    top_indices: list[tuple] | None = None
):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–µ–∂–∏–º–∞ –¥–∏–∞–ª–æ–≥–∞.

    –ó–ê–î–ê–ß–ê 2.3: –î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä top_indices –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ enhance_question_for_index
    —á—Ç–æ–±—ã —É–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ enhanced_question –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ç–æ–ø-3 –∏–Ω–¥–µ–∫—Å–æ–≤.

    Args:
        message: Pyrogram Message –æ–±—ä–µ–∫—Ç
        app: Pyrogram Client
        rags: –°–ª–æ–≤–∞—Ä—å RAG –∏–Ω–¥–µ–∫—Å–æ–≤
        deep_search: True = –≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ, False = –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
        conversation_id: ID –º—É–ª—å—Ç–∏—á–∞—Ç–∞
        skip_expansion: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å Query Expansion (True –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —É–∂–µ —É–ª—É—á—à–µ–Ω)
        top_indices: –¢–æ–ø-K —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤ –æ—Ç Router Agent –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
                    –§–æ—Ä–º–∞—Ç: [(index_name, score), ...]
    """
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ message
    text = message.text
    chat_id = message.chat.id

    # ============ –§–ê–ó–ê 1: QUERY EXPANSION ============
    if not skip_expansion:
        expansion_result = expand_query(text)

        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —É–ª—É—á—à–µ–Ω - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        if expansion_result["used_descry"] and expansion_result["expanded"] != text:
            top_indices = await _get_router_recommendations(expansion_result["expanded"], chat_id)

            await show_expanded_query_menu(
                chat_id=chat_id,
                app=app,
                original=expansion_result["original"],
                expanded=expansion_result["expanded"],
                conversation_id=conversation_id,
                deep_search=deep_search,
                refine_count=0,
                top_indices=top_indices
            )
            return  # –û–∂–∏–¥–∞–µ–º callback –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        text_to_search = expansion_result.get("expanded", text)
    else:
        text_to_search = text

    # ============ –§–ê–ó–ê 2: –í–´–ë–û–† –ò–ù–î–ï–ö–°–ê ============
    user_selected_index = user_states.get(chat_id, {}).get("selected_index")

    if user_selected_index:
        # –†—É—á–Ω–æ–π –≤—ã–±–æ—Ä –∏–Ω–¥–µ–∫—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
        # SonarCloud fix: —Ñ—É–Ω–∫—Ü–∏—è –±–æ–ª—å—à–µ –Ω–µ async, –≤—ã–∑—ã–≤–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        text_to_search, scenario_name, success = _process_manual_index_selection(
            chat_id, text_to_search, user_selected_index, rags, top_indices
        )
        skip_router_agent = success
    else:
        skip_router_agent = False

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Router Agent –µ—Å–ª–∏ —Ä—É—á–Ω–æ–π –≤—ã–±–æ—Ä –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω
    if not skip_router_agent:
        # –ü–µ—Ä–µ–¥–∞–µ–º skip_expansion –∫–∞–∫ skip_enhancement –≤ Router Agent
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —É–∂–µ —É–ª—É—á—à–µ–Ω —á–µ—Ä–µ–∑ expand_query(), –Ω–µ –Ω—É–∂–Ω–æ —É–ª—É—á—à–∞—Ç—å –µ–≥–æ —Å–Ω–æ–≤–∞
        # —á–µ—Ä–µ–∑ enhance_question_for_index() - —ç—Ç–æ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –¥–≤–æ–π–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è
        text_to_search, scenario_name, rag, category = await _run_router_agent(
            text_to_search, rags, top_indices, skip_enhancement=skip_expansion
        )
    else:
        # –ü—Ä–∏ —Ä—É—á–Ω–æ–º –≤—ã–±–æ—Ä–µ –ø–æ–ª—É—á–∞–µ–º rag –∏ category –∏–∑ scenario_name
        rag = rags[scenario_name]
        category = scenario_name

    # ============ –§–ê–ó–ê 3: –ü–û–î–ì–û–¢–û–í–ö–ê –ö–û–ù–¢–ï–ù–¢–ê ============
    try:
        content = build_reports_grouped(scenario_name=scenario_name, report_type=None)
        content = grouped_reports_to_string(content)
    except Exception as content_error:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –æ—Ç—á–µ—Ç–æ–≤: {content_error}")
        content = ""

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
    _validate_search_query(text_to_search)

    # –ü–æ–ª—É—á–∞–µ–º username
    username = await get_username_from_chat(chat_id, app)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
    if conversation_id:
        await _save_user_message_to_conversation(
            chat_id, message.id, text, conversation_id, deep_search
        )

    # ============ –§–ê–ó–ê 4: –í–´–ü–û–õ–ù–ï–ù–ò–ï –ü–û–ò–°–ö–ê ============
    try:
        await _execute_search_and_send_response(
            chat_id=chat_id,
            app=app,
            text_to_search=text_to_search,
            original_text=text,
            deep_search=deep_search,
            content=content,
            rag=rag,
            category=category,
            username=username,
            conversation_id=conversation_id
        )

    except Exception as e:
        error_message = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"
        logging.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        await app.send_message(chat_id, error_message)
    finally:
        # –ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ —Ä–µ–∂–∏–º–∞
        await send_menu(
            chat_id=chat_id,
            app=app,
            text="–ö–∞–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤—ã —Ö–æ—Ç–µ–ª–∏ –±—ã –ø–æ–ª—É—á–∏—Ç—å?",
            reply_markup=make_dialog_markup()
        )

async def run_analysis_pass(
    chat_id: int,
    source_text: str,
    label: str,
    scenario_name: str,
    data: dict,
    prompts: list[tuple[str, int]],
    app: Client,
    transcription_text: str,
    is_show_analysis: bool=True,
    conversation_id: str = None
) -> str:
    """
    –û–¥–∏–Ω ¬´–ø—Ä–æ—Ö–æ–¥¬ª –∞–Ω–∞–ª–∏–∑–∞: –∫—Ä—É—Ç–∏—Ç —Å–ø–∏–Ω–Ω–µ—Ä, –≤—ã–∑—ã–≤–∞–µ—Ç analyze_methodology,
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∏ —Å—Ä–∞–∑—É –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç) —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    """
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ-—Å—Ç–∞—Ç—É—Å —á–µ—Ä–µ–∑ MessageTracker
    msg_ = await track_and_send(
        chat_id=chat_id,
        app=app,
        text=f"‚è≥ –ê–Ω–∞–ª–∏–∑: {label}...",
        message_type="status_message"
    )
    st_ev = threading.Event()
    sp_th = threading.Thread(target=run_loading_animation, args=(chat_id, msg_.id, st_ev, app))
    sp_th.start()

    try:
        audit_text = analyze_methodology(source_text, prompts)

        if is_show_analysis:
            # –ü–æ–ª—É—á–∞–µ–º username
            username = await get_username_from_chat(chat_id, app)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—É—é –æ—Ç–ø—Ä–∞–≤–∫—É —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏–µ–º –∏ MD —Ñ–∞–π–ª–æ–º
            await smart_send_text_unified(
                text=audit_text,
                chat_id=chat_id,
                app=app,
                username=username,
                question=f"–ê–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏: {label}",
                search_type="analysis",
                parse_mode=None,
                conversation_id=conversation_id
            )

            app.edit_message_text(chat_id, msg_.id, f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {label}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î (—Ç–µ–ø–µ—Ä—å –≤—Å—ë ‚Äî —Å–æ—Ç—Ä—É–¥–Ω–∏–∫, place_name, city(–µ—Å–ª–∏ –¥–∏–∑–∞–π–Ω), building).
        save_user_input_to_db(transcript=transcription_text, scenario_name=scenario_name, data=data, label=label, audit_text=audit_text)
        logging.info("–û—Ç—á—ë—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ë–î")
    except OpenAIPermissionError:
        logging.exception("–ù–µ–≤–µ—Ä–Ω—ã–π API_KEY?")
        app.edit_message_text(chat_id, msg_.id, "üö´ –û—à–∏–±–∫–∞: LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (–∫–ª—é—á/—Ä–µ–≥–∏–æ–Ω).")
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞")
        app.edit_message_text(chat_id, msg_.id, f"‚ùå –û—à–∏–±–∫–∞: {e}")
        audit_text = ""
    finally:
        st_ev.set()
        sp_th.join()
        try:
            app.delete_messages(chat_id, msg_.id)
        except Exception:
            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ —É–¥–∞–ª–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è

    return audit_text

async def run_analysis_with_spinner(chat_id: int, processed_texts: dict[int, str], data: dict, app: Client, callback_data: str, transcription_text: str):
    """
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç ¬´—Å–ø–∏–Ω–Ω–µ—Ä¬ª –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –∞–Ω–∞–ª–∏–∑–∞.
    –ü–æ–¥–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç—ã –∏–∑ –ë–î (scenario, report_type, building).
    """
    label = REPORT_MAPPING[callback_data]
    building_name = data.get("type_of_location", "")
    txt = processed_texts.get(chat_id, "")

    if not txt:
        app.send_message(chat_id, "–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ/–æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞—É–¥–∏–æ/—Ç–µ–∫—Å—Ç.")
        return

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º scenario_name –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    if "int_" in callback_data:
        scenario_name = CATEGORY_INTERVIEW
    elif "design" in callback_data:
        scenario_name = "–î–∏–∑–∞–π–Ω"
    else:
        scenario_name = ""

    report_type_desc = mapping_report_type_names.get(callback_data, label)

    prompts_list = []
    if not building_name:
        building_name = mapping_building_names[building_name]

    if scenario_name and building_name and report_type_desc:
        try:
            prompts_list = fetch_prompts_for_scenario_reporttype_building(
                scenario_name=scenario_name,
                report_type_desc=report_type_desc,
                building_type=building_name
            )
        except Exception as e:
            logging.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–±–æ—Ä–∫–µ –ø—Ä–æ–º–ø—Ç–æ–≤")

    json_prompts = [(p, rp) for (p, rp, is_json_prompt) in prompts_list if is_json_prompt]
    ordinary_prompts = [(p, rp) for (p, rp, is_json_prompt) in prompts_list if not is_json_prompt]

    if scenario_name == CATEGORY_INTERVIEW and report_type_desc == "–û–±—â–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã":
        logging.info("–ì–æ—Ç–æ–≤–ª—é –¥–≤–∞ –æ—Ç—á—ë—Ç–∞")
        # prompts_list -> [(prompt_text, run_part, is_json_prompts), ...]

        # –°–≥—Ä—É–ø–ø–∏—Ä—É–µ–º. –ù–∞–ø—Ä–∏–º–µ—Ä, part1 = –≤—Å–µ –ø—Ä–æ–º–ø—Ç—ã, –≥–¥–µ run_part=1
        #               part2 = –≤—Å–µ –ø—Ä–æ–º–ø—Ç—ã, –≥–¥–µ run_part=2
        part1 = [(p, rp) for (p, rp) in ordinary_prompts if rp == 1]
        part2 = [(p, rp) for (p, rp) in ordinary_prompts if rp == 2]

        # –ï—Å–ª–∏ run_part –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω ‚Äî part1 –∏–ª–∏ part2 –±—É–¥—É—Ç –ø—É—Å—Ç—ã,
        # –º–æ–∂–Ω–æ –ø–æ–¥—Å—Ç—Ä–∞—Ö–æ–≤–∞—Ç—å—Å—è –ø—Ä–æ–≤–µ—Ä–∫–æ–π. –í –ø—Ä–æ—Å—Ç–æ–º —Å–ª—É—á–∞–µ:
        if part1:
            # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥
            result1 = await run_analysis_pass(
                chat_id=chat_id,
                source_text=txt,
                label=label,
                scenario_name=scenario_name,
                data=data,
                app=app,
                prompts=part1,
                is_show_analysis=False,
                transcription_text=transcription_text
            )

            logging.info("–û—Ç—á–µ—Ç —Å –æ–±—â–∏–º–∏ —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω")
            # –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (—É–∂–µ –≤–Ω—É—Ç—Ä–∏ run_analysis_pass)
        if part2:
            # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥
            result2 = await run_analysis_pass(
                chat_id=chat_id,
                source_text=txt,
                label=label,
                scenario_name=scenario_name,
                data=data,
                app=app,
                prompts=part2,
                is_show_analysis=False,
                transcription_text=transcription_text
            )

            logging.info("–û—Ç—á–µ—Ç —Å –Ω–µ–∏–∑—É—á–µ–Ω–Ω—ã–º–∏ —Ñ–∞–∫—Ç–æ—Ä–∞–º–∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω")
            # –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (—É–∂–µ –≤–Ω—É—Ç—Ä–∏ run_analysis_pass)
        await run_analysis_pass(
            chat_id=chat_id,
            source_text=result1 + "\n" + result2,
            label=label,
            scenario_name=scenario_name,
            data=data,
            app=app,
            prompts=json_prompts,
            is_show_analysis=True,
            transcription_text=transcription_text
        )

        logging.info("–ü—Ä–æ–≤–µ–¥—ë–Ω –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    else:
        # –õ—é–±–æ–π –¥—Ä—É–≥–æ–π –æ—Ç—á—ë—Ç ‚Äî –æ–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º run_part
        # –°—á–∏—Ç–∞–µ–º, —á—Ç–æ prompts_list —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–¥–∏–Ω –Ω–∞–±–æ—Ä (–∏–ª–∏ –º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–æ–≤),
        # –Ω–æ –≤—Å–µ –æ–Ω–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤ –æ–¥–∏–Ω –≤—ã–∑–æ–≤ analyze_methodology.
        result = await run_analysis_pass(
            chat_id=chat_id,
            source_text=txt,
            label=label,
            scenario_name=scenario_name,
            data=data,
            app=app,
            prompts=ordinary_prompts,
            is_show_analysis=False,
            transcription_text=transcription_text
        )

        logging.info("–û—Ç—á—ë—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω")

        await run_analysis_pass(
            chat_id=chat_id,
            source_text=result,
            label=label,
            scenario_name=scenario_name,
            data=data,
            app=app,
            prompts=json_prompts,
            is_show_analysis=True,
            transcription_text=transcription_text
        )

        logging.info("–ü—Ä–æ–≤–µ–¥—ë–Ω –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")

    if scenario_name == CATEGORY_INTERVIEW:
        await send_menu(chat_id, app, "–ö–∞–∫–æ–π –æ—Ç—á—ë—Ç —Ö–æ—Ç–∏—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∞–ª—å—à–µ?", interview_menu_markup())
    elif scenario_name == "–î–∏–∑–∞–π–Ω":
        await send_menu(chat_id, app, "–ö–∞–∫–æ–π –æ—Ç—á—ë—Ç —Ö–æ—Ç–∏—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –¥–∞–ª—å—à–µ?", design_menu_markup())

    send_main_menu(chat_id, app)
